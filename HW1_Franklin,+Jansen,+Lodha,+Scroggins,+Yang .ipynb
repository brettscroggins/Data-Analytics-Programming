{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Homework 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem #1\n",
    "\n",
    "For this problem, we divide the process into three parts. First, we decide on what the computer plays by using generate_computer_choice function. This function takes the keys of the maximum values recorded in the record dictionary. Using len(max_keys),if three keys return from max_value, we know three moves are played equally and computer will play a move generated by the random function (this is also what happens in round 1). If there are two keys, meaning the highest two are equal to each other, computer will play whichever will result in a tie or win by looking through the 'opposites' dictionary. For example, if 'rock' and 'paper' were played equally and more than 'scissor', then the computer will choose to play 'paper', which will result in either a tie or win. \n",
    "Then we take the input from the player. We use a infinite while loop to keep the game going. We set human_choice equal to empty string to enter another while loop that examines if input is valid. We turn the input into lower case for validation purpose. We examine whether the input is one of 'rock','pepr','scissor' or 'quit'. If input is not valid, we will ask for input again. If player choose to quit, we terminate the loop and return the rounds played and times that player won.\n",
    "Lastly, when the inputs are valid and are not 'quit', we evaluate the computer choice and human_choice. Using the opposites dictionary, we decide which party wins; if two chooses the same move, it will be a tie. We print the result to screen and add one time to the round data and record the move in the record dictionary. The while loop continues until player inputs 'quit'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's play Rock, Paper, Scissors. What's your move (rock, paper, scissors)__? To exit this game, please enter quit\n",
      "rock\n",
      "You played rock and you won!\n",
      "Let's play Rock, Paper, Scissors. What's your move (rock, paper, scissors)__? To exit this game, please enter quit\n",
      "paper\n",
      "It is a tie!\n",
      "Let's play Rock, Paper, Scissors. What's your move (rock, paper, scissors)__? To exit this game, please enter quit\n",
      "scissors\n",
      "Let's play Rock, Paper, Scissors. What's your move (rock, paper, scissors)__? To exit this game, please enter quit\n",
      "quit\n",
      "Thank you for playing. We played 2 rounds and you won 1 times.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "record = {\"rock\":0,\"scissor\":0,\"paper\":0}\n",
    "opposites = {'rock': 'paper', 'paper': 'scissor', 'scissor': 'rock'}\n",
    "rounds = 0\n",
    "human_win = 0\n",
    "\n",
    "def generate_computer_choice():\n",
    "#generate computer choice based on previous games\n",
    "\n",
    "    max_value = max(record.values())\n",
    "\n",
    "    if max_value == 0:\n",
    "        return random.choice(record.keys())\n",
    "    \n",
    "    max_keys = [key for key, value in record.items() if value == max_value]\n",
    "    #loop through the values in record and return keys with maximum values\n",
    "    if len(max_keys) == 1:\n",
    "        return opposites[max_keys[0]]\n",
    "\n",
    "    if len(max_keys) == 3:\n",
    "        return random.choice(record.keys())\n",
    "\n",
    "    if opposites[max_keys[0]] == max_keys[1]:\n",
    "        return max_keys[1]\n",
    "    \n",
    "    else:\n",
    "        return max_keys[0]   \n",
    "\n",
    "   \n",
    "\n",
    "while True:\n",
    "    \n",
    "    computer_choice = generate_computer_choice()\n",
    "    human_choice=''\n",
    "\n",
    "    while human_choice not in record and human_choice != 'quit':\n",
    "        \n",
    "        print 'Let\\'s play Rock, Paper, Scissors. What\\'s your move (rock, paper, scissors)__? To exit this game, please enter quit'\n",
    "        human_choice = raw_input()\n",
    "        #take the input from player\n",
    "        \n",
    "        human_choice = human_choice.lower()\n",
    "        # take the lower case of input for validation\n",
    "        \n",
    "    if human_choice == 'quit':\n",
    "    # return results of the games when human choose to quit game\n",
    "        print 'Thank you for playing. We played',rounds, 'rounds and you won',human_win,'times.'\n",
    "        break\n",
    "    \n",
    "    if human_choice == computer_choice:\n",
    "        print 'It is a tie!'\n",
    "    elif opposites[human_choice] == computer_choice:\n",
    "        print 'You played',human_choice,'and you lost!'\n",
    "    else:\n",
    "        print 'You played',human_choice,'and you won!'\n",
    "        human_win += 1\n",
    "                \n",
    "    rounds += 1      \n",
    "    #record rounds played \n",
    "             \n",
    "    record[human_choice] += 1\n",
    "     #record each move played"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Problem 2\n",
    "\n",
    "This script works by reading in every line of the FloridaVoters file. For each line, it uses a function with re.findall and regular expressions to identify if the line contains the name of a county. If the line contains the name of a county, the line is stripped to contain only the county line. The next following line is the republic line and the line after that is the democrat line. A tuple is created with these three values and added to the list of voters.  After that, the next line is read in and the start for lines with a county begins again.  The tuples are sorted according to the third column and then there is a print statement to print the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LAFAYETTE 1373 2672\n",
      "GLADES 2190 3110\n",
      "LIBERTY 720 3372\n",
      "UNION 2752 3579\n",
      "GILCHRIST 5789 3652\n",
      "FRANKLIN 2234 4319\n",
      "HOLMES 5282 4434\n",
      "GULF 4234 4521\n",
      "HARDEE 4859 4702\n",
      "HAMILTON 2154 4796\n",
      "DIXIE 3314 4839\n",
      "CALHOUN 2201 5324\n",
      "WASHINGTON 7101 5687\n",
      "JEFFERSON 2636 5802\n",
      "BAKER 6963 5813\n",
      "BRADFORD 6878 6533\n",
      "TAYLOR 3950 6915\n",
      "MADISON 2992 7158\n",
      "DESOTO 4870 7181\n",
      "OKEECHOBEE 7755 7756\n",
      "HENDRY 5862 7999\n",
      "WAKULLA 7374 8889\n",
      "LEVY 11665 9509\n",
      "WALTON 25609 10013\n",
      "SUWANNEE 10745 11126\n",
      "NASSAU 32958 14013\n",
      "COLUMBIA 15790 14797\n",
      "JACKSON 9626 15706\n",
      "MONROE 20602 17614\n",
      "HIGHLANDS 27100 19997\n",
      "PUTNAM 17067 20606\n",
      "GADSDEN 4372 22161\n",
      "SUMTER 47158 22977\n",
      "FLAGLER 30047 24734\n",
      "OKALOOSA 75154 25172\n",
      "SANTA ROSA 73627 26114\n",
      "MARTIN 53800 27358\n",
      "INDIAN RIVER 47794 28204\n",
      "CITRUS 46373 30440\n",
      "BAY 57456 30733\n",
      "CLAY 76584 31285\n",
      "CHARLOTTE 54421 35602\n",
      "ST. JOHNS 88385 39531\n",
      "HERNANDO 51254 42499\n",
      "COLLIER 100167 45511\n",
      "LAKE 93604 67237\n",
      "MANATEE 96063 67926\n",
      "ESCAMBIA 90265 70180\n",
      "OSCEOLA 44594 75657\n",
      "ST. LUCIE 59626 76163\n",
      "MARION 97306 76268\n",
      "ALACHUA 47329 77996\n",
      "SARASOTA 125872 89711\n",
      "SEMINOLE 107833 91686\n",
      "LEON 54554 103140\n",
      "PASCO 125305 104324\n",
      "LEE 180718 114633\n",
      "VOLUSIA 121402 124136\n",
      "BREVARD 167129 127435\n",
      "POLK 140619 143799\n",
      "PINELLAS 223077 221968\n",
      "DUVAL 210195 229501\n",
      "ORANGE 206174 303458\n",
      "HILLSBOROUGH 257436 314265\n",
      "PALM BEACH 245452 367236\n",
      "MIAMI-DADE 362161 539367\n",
      "BROWARD 249762 566185\n",
      "Total 4377713 4637026\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function close>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re #this is the regular expression module \n",
    "fp=open('C:\\Users\\emery\\Desktop\\Data Analytics Programming\\FloridaVoters.html', 'r') #open the file with the FloridaVoters data\n",
    "\n",
    "line=fp.readline()  #read the first line of the file\n",
    "\n",
    "voterlist=[]\n",
    "def findcounties(s): #write a function to find the counties in the data (using re.findall)\n",
    "    return re.findall('<td>[a-zA-Z][a-zA-Z]',s) #find lines that contain the county\n",
    "            \n",
    "while line is not '': #determined when to close the file\n",
    "    county=findcounties(line) #find lines of text file that have counties\n",
    "    if county != []: \n",
    "#if there is a county, then strip the unnecessary characters from the line and store as countyname\n",
    "        countyname=line.lstrip('<td>').rstrip().rstrip('</<td>')\n",
    "#the following line is the repub data\n",
    "        repub=fp.readline().lstrip('<td>').rstrip().rstrip('</<td>')\n",
    "        repub=int(re.sub('[^\\w]','', repub))\n",
    "#remove commas and turn repub data into an integer so that it can be sorted\n",
    "        democrats=fp.readline().lstrip('<td>').rstrip().rstrip('</<td>')\n",
    "        democrats=int(re.sub('[^\\w]','', democrats))\n",
    "#remove commas and turn democrats data into an integer so that it can be sorted\n",
    "        tup=(countyname, repub, democrats)\n",
    "#create a tuple with the county data\n",
    "        voterlist.append(tup) \n",
    "#add the tuple to the list\n",
    "    line=fp.readline()\n",
    "#read in a new line\n",
    "\n",
    "sortedcounties=sorted(voterlist,key=lambda x: x[2]) #sort the list of county data according to the third column\n",
    "\n",
    "for county in sortedcounties:\n",
    "    print county[0], county[1], county[2] #print tuples in correct format\n",
    "\n",
    "#reads new line in\n",
    "      \n",
    "fp.close #closes the file when you are done #close file\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem #3\n",
    "\n",
    "- For question 3, the starting point was to import the document with the deletion of certain formatting characters.\n",
    "- Part A makes a new list of all quotes, named new_text, was formed and formatted in the (quote) -(author) format. This list is iterated for the entire file.\n",
    "- Part B, a function named split_string is defined; this function takes an individual quote, deletes all formatting characters that are not in the \\w list except for spaces - the spaces are left to keep individual words seperate. Once there are only words and spaces left, the function returns a list of all words in each individual quote.\n",
    "- Part C creates a posting list dictionary with the use of a while loop and the Counter function. The while loop seperates the text, counts the occurances of the words, and then adds a line to the dictionary with the quote being the key, and the value being the list of words with their respective counts.\n",
    "- Part D is the reverse postings list. In this, the first goal is to create a list of all unique words in the entire text file. This was done with the list(set()) functions to create a list with no repeated words. After this was done, two while loops are iterated through with the output being a dictionary who's keys are the unique words, and the values being the quote and the number of iterations of the unique words in each quote.                                 \n",
    "- For Part E, we created a function that takes two arguments: an int called quote_number, and a string called word.  We made the variable input_word which takes the argument word and makes it a lower case string. Then we create a variable st, which is the quote corresponding to the number input as an argument in the function. After that, st_lower is created to clean up st – that is, we replaced all the commas, dashes, periods, semicolons and apostrophes with spaces. All of these words were separated using the list function and put into a list called words. Then we set up two variables, i and counter set up an iterator and a counter respectively. To get the word count of the input string in the selected quote, we used a while loop to loop through the list of words and count the number of times the input word was used – this count was assigned to the counter variable as the loop cycled. We that created a function using a for loop to make a dictionary of the word count of the other words in the quote. We found the maximum value in this dictionary by using the max() function and the .values() function. Then we could calculate the term frequency (TF) by dividing the float of our counter variable by the maximum word count for another word in the quote. To find the IDF value we make a while loop to loop through the list of quotes (new_text). Within that loop we write an if statement that if the input word is in any of the quotes in the new_text list that we count it. Then we add the count as a value to our dictionary rev_postings_list whose corresponding key is the quote the word is in. Finally to get the idf we take the log (from math) of all of the quotes divided by the number of times we saw the word in the quotes. Then the tf –idf value equals tf*idf which we return to finish off our function.\n",
    "- For Part F, we created a function that takes no arguments. When the function is called, the program asks the user to enter a word for which they would like to search to find the tf-idf value for every quote. This input is store in the variable user_input. User_input is turned lowercase using the .lower() function and stored under input_lower. We create an empty dictionary to store our results called results_dict. Then we create a while loop to iterate through our list of quotes (new_text). Within the loop, if the word that was searched for is in one of the quotes the quote is added to our result_dict as a key and the tf-idf value is add as the value ( we call upon the tf-idf function created in part E for this). The loop iterates through all of the quotes, and then prints the results_dict. \n",
    "- For part G we take words separated by a space as an argument. We put those words into a string using the split_string function made previously in problem 3. We iterate through our list of quotes (new_text) using a while loop. In the while loop we placed a for loop to go through our list of words, inside that loop we placed an if statement to find that word in the quote list. Once we find the word we call the tf-idf function from part f and sum up that tf-idf for all the words in that function. That sum is assigned as the value in our final dictionary with the key being the initial quote we found that matched a word from our list. Finally we print the final dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "from collections import Counter\n",
    "\n",
    "# Each user will need to edit file path for their individual path.\n",
    "text_file = open(\"C:\\Users\\emery\\Desktop\\Data Analytics Programming\\quotes.txt\", \"r\")\n",
    "lines = text_file.readlines()\n",
    "\n",
    "# To delete formatting characters that are not needed.\n",
    "n=0\n",
    "for i in lines:\n",
    "    lines[n]=i.rstrip(\"\\r\\n\")\n",
    "    n+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In any moment of decision, the best thing you can do is the right thing. The worst thing you can do is nothing. -Theodore Roosevelt\n"
     ]
    }
   ],
   "source": [
    "# Create a new list to hold all quotes as strings\n",
    "new_text = []\n",
    "\n",
    "i = 0\n",
    "\n",
    "while i < len(lines):\n",
    "    \n",
    "    # This will format the quotes into the desired look\n",
    "    new_text.append (lines[i] + ' -' + lines[i+1])\n",
    "    \n",
    "    i += 2\n",
    "\n",
    "# Samples problem\n",
    "print new_text[80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['in', 'any', 'moment', 'of', 'decision', 'the', 'best', 'thing', 'you', 'can', 'do', 'is', 'the', 'right', 'thing', 'the', 'worst', 'thing', 'you', 'can', 'do', 'is', 'nothing', 'theodore', 'roosevelt']\n"
     ]
    }
   ],
   "source": [
    "# The split_string funtion is defined to take a quote, delete characters \n",
    "# not in the \\w list with the exception of a (space). The (space) is kept\n",
    "# to then separate at that space. Lastly, it returns all words.\n",
    "\n",
    "def split_string(st):\n",
    "\n",
    "    st = st.lower()\n",
    "    st = re.sub('[^\\w ]', '', st)\n",
    "    words = st.split(\" \")\n",
    "\n",
    "    return words\n",
    "    \n",
    "# Sample Problem\n",
    "print split_string(new_text[80])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'the': 2, 'heart': 1, 'knows': 1, 'reasons': 1, 'of': 1, 'mind': 1, 'blaise': 1, 'pascal': 1, 'which': 1, 'nothing': 1, 'has': 1, 'its': 1})\n"
     ]
    }
   ],
   "source": [
    "# Define the postings_list as an empty dictionary to define later\n",
    "postings_list = {}\n",
    "\n",
    "# This while loop will create an entire postings_list{} dictionary\n",
    "i = 0\n",
    "while i < len(new_text):\n",
    "    \n",
    "    st = new_text[i]\n",
    "    st = st.lower()\n",
    "    st = re.sub('[^\\w ]', '', st)\n",
    "    words = st.split(\" \")\n",
    "\n",
    "    postings_list[new_text[i]] = Counter(words)\n",
    "        \n",
    "    i += 1\n",
    "\n",
    "# Sample Problem\n",
    "print postings_list['The heart has its reasons, of which the mind knows nothing. -Blaise Pascal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a complete list of all unique words from the text file\n",
    "\n",
    "# Use the split_string function to put all words in a list\n",
    "allwords = [split_string(items) for items in lines]\n",
    "\n",
    "# Remove the imbeded lists to form one long list\n",
    "allwords = sum(allwords, [])\n",
    "\n",
    "# The step removes the duplicate words\n",
    "allwords = list(set(allwords))\n",
    "\n",
    "# This last portion deletes the first word of the list as it is a '' item.\n",
    "allwords.pop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('An actor is at most a poet and at least an entertainer. -Marlon Brando', 1)\n"
     ]
    }
   ],
   "source": [
    "# Create the rev_postings_list as an empty dictionary\n",
    "rev_postings_list = {}\n",
    "\n",
    "j = 0\n",
    "\n",
    "while j < len(allwords):\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    while i < len(new_text):\n",
    "        \n",
    "        if allwords[j] in new_text[i].lower():\n",
    "\n",
    "            counter = new_text[i].lower().count(allwords[j])\n",
    "            rev_postings_list[allwords[j]] = new_text[i],counter\n",
    "\n",
    "        i += 1\n",
    "    \n",
    "    j+= 1\n",
    "    \n",
    "# Sample Problem\n",
    "print rev_postings_list['entertainer']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.02217186745\n"
     ]
    }
   ],
   "source": [
    "#function takes the quote number and word we are looking for as arguments\n",
    "def tf_idf(quote_number, word):\n",
    "    #word we are looking for in lower case\n",
    "    input_word = word.lower()\n",
    "    #we have the quote in lower case\n",
    "    st = new_text[quote_number].lower()\n",
    "    #st_lower is the lower case quote with all commas, periods, apostrophes, semicolons, dashes, etc replaced with spaces\n",
    "    st_lower = re.sub('[^\\w _]', '', st)\n",
    "    #words is a list of all the words in the string\n",
    "    words = st_lower.split(\" \")\n",
    "    #iterator variable\n",
    "    i = 0\n",
    "    #counter variable\n",
    "    counter = 0\n",
    "    #while loop to iterate through our list\n",
    "    while i < len(words):\n",
    "        #if the word that the user entered is in our list\n",
    "        if input_word == words[i]:\n",
    "            #our counter for that word goes up\n",
    "            counter += words[i].count(input_word)\n",
    "            \n",
    "        i +=1        \n",
    "        #function to get the word count of other words\n",
    "    def popularWords(words):\n",
    "        dic = {}\n",
    "        for word in words:\n",
    "            dic.setdefault(word,0)\n",
    "            dic[word] += 1\n",
    "        return dic\n",
    "    #maximum number of times any word is used\n",
    "    max_count = max(popularWords(words).values())\n",
    "    #TF\n",
    "    tf_func = float(counter)/max_count\n",
    "    #Finding the IDF\n",
    "    import math\n",
    "    #empty dictionary\n",
    "    rev_postings_list = {}\n",
    "    #setting our input argument for the word we just found the TF for\n",
    "    input_arg = input_word\n",
    "    #set up an iterator variable\n",
    "    i=0\n",
    "    #while loop to iterate through the list of quotes\n",
    "    while i < len(new_text):\n",
    "        #if the word is in the quote\n",
    "        if input_arg in split_string(new_text[i].lower()):\n",
    "            #we count it\n",
    "            counter = new_text[i].lower().count(input_arg)\n",
    "            #and add it to our new dictionary\n",
    "            rev_postings_list[new_text[i]] = counter\n",
    "        i +=1\n",
    "    #getting the IDF\n",
    "    idf_func = math.log((float(len(new_text))/len(rev_postings_list)),10)\n",
    "    #Getting the TF-IDF\n",
    "    tf_idf_func = tf_func*idf_func\n",
    "    return tf_idf_func\n",
    "#Sample Problem\n",
    "print tf_idf(18,'object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Such is the delicacy of man alone, that no object is produced to his liking. He finds that in everything there is need for improvement. The whole industry of human life is employed not in procuring the supply of our three humble necessities, food, clothes and lodging, but in procuring the conveniences of it according to the nicety and delicacy of our tastes. -Adam Smith': 0.4088687469790214, 'To defend Western Europe we have to let the Pentagon buy all these tanks and guns and things, and the Pentagon is unable to buy any object that that costs less than a condominium in Vail. If the Pentagon needs, say, fruit, it will argue that it must have fruit that can withstand the rigors of combat conditions, and it will wind up purchasing the FX-700 Seedless Tactical Grape, which will cost $160,000 per bunch, and will have an 83 percent failure rate. -Dave Barry': 0.4088687469790214, 'Women are the only realists; their whole object in life is to pit their realism against the extravagant, excessive, and occasionally drunken idealism of men. -GK Chesterton': 1.0221718674475535, 'The object of war is not to die for your country but to make the other bastard die for his. -George Patton': 1.0221718674475535, 'War - an act of violence whose object is to constrain the enemy, to accomplish our will. -George Washington': 1.0221718674475535, 'This does not mean that the enemy is to be allowed to escape. The object is to make him believe that there is a road to safety, and thus prevent his fighting with the courage of despair. After that, you may crush him. -Sun Tzu': 0.5110859337237768, 'The object of teaching a child is to enable him to get along without a teacher. -Elbert Hubbard': 1.0221718674475535}\n"
     ]
    }
   ],
   "source": [
    "def quote_search_using_a_single_word(user_input):\n",
    "    #Selecting the Word \n",
    "    #user_input = raw_input(\"Please enter the word you would like to search for: \")\n",
    "    input_lower = user_input.lower()\n",
    "    results_dict = {}\n",
    "    j=0\n",
    "    while j < len(new_text)-1:\n",
    "        if \" \"+input_lower+\" \" in new_text[j]:\n",
    "            \n",
    "            results_dict[new_text[j]] = tf_idf(j,user_input)\n",
    "        j+=1\n",
    "    print results_dict\n",
    "#Sample Problem\n",
    "quote_search_using_a_single_word('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the words you want to search for separated by a space: object fashion purple\n",
      "{'Such is the delicacy of man alone, that no object is produced to his liking. He finds that in everything there is need for improvement. The whole industry of human life is employed not in procuring the supply of our three humble necessities, food, clothes and lodging, but in procuring the conveniences of it according to the nicety and delicacy of our tastes. -Adam Smith': 27.50871126724561, 'To defend Western Europe we have to let the Pentagon buy all these tanks and guns and things, and the Pentagon is unable to buy any object that that costs less than a condominium in Vail. If the Pentagon needs, say, fruit, it will argue that it must have fruit that can withstand the rigors of combat conditions, and it will wind up purchasing the FX-700 Seedless Tactical Grape, which will cost $160,000 per bunch, and will have an 83 percent failure rate. -Dave Barry': 44.17060874478612, 'Women are the only realists; their whole object in life is to pit their realism against the extravagant, excessive, and occasionally drunken idealism of men. -GK Chesterton': 24.573455760547827, 'The object of war is not to die for your country but to make the other bastard die for his. -George Patton': 17.190094897377932, 'War - an act of violence whose object is to constrain the enemy, to accomplish our will. -George Washington': 14.64971509329684, 'The leading cause of death among fashion models is falling through street grates. -Dave Barry': 29.520083495517525, 'He wrapped himself in quotations--as a beggar would enfold himself in the purple of Emperors. -Rudyard Kipling': 18.357613824686524, 'This does not mean that the enemy is to be allowed to escape. The object is to make him believe that there is a road to safety, and thus prevent his fighting with the courage of despair. After that, you may crush him. -Sun Tzu': 19.747819688224297, 'The object of teaching a child is to enable him to get along without a teacher. -Elbert Hubbard': 13.500293832476792}\n"
     ]
    }
   ],
   "source": [
    "def quote_search_using_mult_words(inputWords):\n",
    "    import re \n",
    "    #list of the words from user input\n",
    "    inputList = split_string(inputWords)\n",
    "    final_dict = {}\n",
    "    k=0\n",
    "    #iterating through our list of quotes\n",
    "    while k < len(new_text)-1:\n",
    "        #iterating through our list\n",
    "        for value in inputList:\n",
    "            #if the word in the list is in the quote\n",
    "            if \" \"+value+\" \" in new_text[k]:\n",
    "                #a list of each word in the quote\n",
    "                words = split_string(new_text[k])\n",
    "                sumTF_IDF = 0\n",
    "                #for every word in our quote \n",
    "                for word in words:\n",
    "                    #find the tf-idf and add it to a running total\n",
    "                    sumTF_IDF += tf_idf(k,word) \n",
    "                #add the quote as a key to the dictionary with the sum of the tf-idf's    \n",
    "                final_dict[new_text[k]]=sumTF_IDF\n",
    "        k +=1\n",
    "    print final_dict\n",
    "#Sample Problem\n",
    "user_input = raw_input(\"Enter the words you want to search for separated by a space: \")\n",
    "quote_search_using_mult_words(user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
